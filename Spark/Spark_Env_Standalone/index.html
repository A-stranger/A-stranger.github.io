<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Spark环境搭建（二）Standalone模式 | 学习大数据</title><meta name="keywords" content="Spark环境搭建"><meta name="author" content="XiaoQu"><meta name="copyright" content="XiaoQu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Spark环境搭建（二）Standalone模式  伪分布式配置包括 Hadoop配置，Master, Worker的通信地址和Web UI的地址 spark-env.sh（Server）1234567# 如果Worker提示JAVA_HOME is not set, 在此文件配置一下JAVA_HOME# JAVA_HOME&#x3D;$&amp;#123;JAVA_HOME&amp;#125;HADOOP_CONF_DI">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark环境搭建（二）Standalone模式">
<meta property="og:url" content="http://www.studybigdata.cn/Spark/Spark_Env_Standalone/index.html">
<meta property="og:site_name" content="学习大数据">
<meta property="og:description" content="Spark环境搭建（二）Standalone模式  伪分布式配置包括 Hadoop配置，Master, Worker的通信地址和Web UI的地址 spark-env.sh（Server）1234567# 如果Worker提示JAVA_HOME is not set, 在此文件配置一下JAVA_HOME# JAVA_HOME&#x3D;$&amp;#123;JAVA_HOME&amp;#125;HADOOP_CONF_DI">
<meta property="og:locale">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2023-01-15T07:55:26.000Z">
<meta property="article:modified_time" content="2023-01-15T11:13:22.547Z">
<meta property="article:author" content="XiaoQu">
<meta property="article:tag" content="Spark环境搭建">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://www.studybigdata.cn/Spark/Spark_Env_Standalone/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="code-qvYtDCUlcS"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?057fccfc2b1bef4c0d79224d80660be0";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Spark环境搭建（二）Standalone模式',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-01-15 19:13:22'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/jin.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">90</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">50</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">23</div></a></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">学习大数据</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Spark环境搭建（二）Standalone模式</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-01-15T07:55:26.000Z" title="Created 2023-01-15 15:55:26">2023-01-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-01-15T11:13:22.547Z" title="Updated 2023-01-15 19:13:22">2023-01-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Spark/">Spark</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Spark环境搭建（二）Standalone模式"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div><article class="post-content" id="article-container"><h1 style="color:red; text-align:center;color:red;">Spark环境搭建（二）Standalone模式</h1>

<h2 id="伪分布式"><a href="#伪分布式" class="headerlink" title="伪分布式"></a>伪分布式</h2><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>包括 <code>Hadoop</code>配置，Master, Worker的通信地址和Web UI的地址</p>
<h5 id="spark-env-sh（Server）"><a href="#spark-env-sh（Server）" class="headerlink" title="spark-env.sh（Server）"></a>spark-env.sh（Server）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果Worker提示JAVA_HOME is not <span class="built_in">set</span>, 在此文件配置一下JAVA_HOME</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">JAVA_HOME=<span class="variable">$&#123;JAVA_HOME&#125;</span></span></span><br><span class="line"></span><br><span class="line">HADOOP_CONF_DIR=/opt/bigdata/hadoop/default/etc/hadoop #读写HDFS</span><br><span class="line">SPARK_MASTER_HOST=node0  # Master节点</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">日志服务器HistoryServer会去指定的位置读取执行事件日志</span></span><br><span class="line">SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node0:9000/shared/spark-logs&quot;</span><br></pre></td></tr></table></figure>

<h5 id="spark-default-conf（Client）"><a href="#spark-default-conf（Client）" class="headerlink" title="spark-default-conf（Client）"></a>spark-default-conf（Client）</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node0 conf]$ mv spark-defaults.conf.template spark-defaults.conf</span><br><span class="line">[zhangsan@node0 conf]$ vim spark-defaults.conf</span><br><span class="line">spark.master                     spark://node0:7077</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">spark applications 执行的事件日志会存放到指定的位置</span></span><br><span class="line">spark.eventLog.enabled           true</span><br><span class="line">spark.eventLog.dir               hdfs://node0:9000/shared/spark-logs</span><br></pre></td></tr></table></figure>

<h5 id="Slave"><a href="#Slave" class="headerlink" title="Slave"></a>Slave</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node1 conf]$ mv slaves.template slaves</span><br><span class="line">[zhangsan@node1 conf]$ vim slaves </span><br><span class="line">localhost</span><br></pre></td></tr></table></figure>

<h4 id="启动Spark集群"><a href="#启动Spark集群" class="headerlink" title="启动Spark集群"></a>启动Spark集群</h4><h5 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动HDFS</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node0 sbin]$ start-dfs.sh </span><br></pre></td></tr></table></figure>

<h5 id="启动History-Server"><a href="#启动History-Server" class="headerlink" title="启动History Server"></a>启动History Server</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启动HistoryServer</span><br><span class="line">[zhangsan@node0 sbin]$ ./start-history-server.sh </span><br></pre></td></tr></table></figure>

<h5 id="启动Spark"><a href="#启动Spark" class="headerlink" title="启动Spark"></a>启动Spark</h5><p>启动<code>Master</code>和<code>Worker</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node0 sbin]$ ./start-all.sh </span><br><span class="line">[zhangsan@node1 sbin]$ jps</span><br><span class="line">5393 Worker</span><br><span class="line">5300 Master</span><br><span class="line">4582 NodeManager</span><br><span class="line">5447 Jps</span><br><span class="line">4216 SecondaryNameNode</span><br><span class="line">4376 ResourceManager</span><br><span class="line">4027 DataNode</span><br><span class="line">3871 NameNode</span><br><span class="line">14845 HistoryServer</span><br></pre></td></tr></table></figure>

<h4 id="Web-UI查看"><a href="#Web-UI查看" class="headerlink" title="Web UI查看"></a>Web UI查看</h4><p>可以在<code>windows</code>系统中配置一下<code>hosts</code>映射。</p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># C:\Windows\System32\drivers\etc\hosts</span><br><span class="line">192.168.179.100	node0</span><br></pre></td></tr></table></figure>

<p><strong>Master : 8080</strong></p>
<p><strong>Worker : 8081</strong></p>
<p><strong>HistoryServer：18080</strong></p>
<p><strong>Driver：4040</strong></p>
<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node0 bin]$ ./spark-shell --master spark://node0:7077</span><br><span class="line">[GCC 7.5.0] :: Anaconda, Inc. on linux</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">22/02/15 12:41:57 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Setting default log level to &quot;WARN&quot;.</span><br><span class="line">To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).</span><br><span class="line">22/02/15 12:41:59 WARN spark.SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &#x27;_/</span><br><span class="line">   /__ / .__/\_,_/_/ /_/\_\   version 3.0.3</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Python version 3.7.11 (default, Jul 27 2021 14:32:16)</span><br><span class="line">SparkSession available as &#x27;spark&#x27;.</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">转换算子，不触发计算</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">动作算子Action，触发计算</span></span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; var wordcount = sc.textFile(<span class="string">&quot;hdfs:///input/bigdata.txt&quot;</span>).flatMap(line =&gt; line.split(<span class="string">&quot; &quot;</span>)).map(word =&gt; (word,1)).reduceByKey(_+_)</span></span><br><span class="line">wordcount: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[11] at reduceByKey at &lt;console&gt;:24</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">scala&gt; </span><span class="language-bash">wordcount.collect()</span></span><br><span class="line">res3: Array[(String, Int)] = Array((hello,2), (bigdata,2), (study,2))</span><br></pre></td></tr></table></figure>

<p>可以在 <a target="_blank" rel="noopener" href="http://node0:4040/">http://node0:4040</a> 下查看<code>driver</code>下job的运行情况。</p>
<h2 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h2><h4 id="Spark配置"><a href="#Spark配置" class="headerlink" title="Spark配置"></a>Spark配置</h4><p>包括 <code>Hadoop</code>配置，<code>Master</code>, <code>Worker</code>的通信地址和<code>Web UI</code>的地址</p>
<h5 id="spark-env-sh（Server）-1"><a href="#spark-env-sh（Server）-1" class="headerlink" title="spark-env.sh（Server）"></a>spark-env.sh（Server）</h5><h5 id="spark-default-conf（Client）-1"><a href="#spark-default-conf（Client）-1" class="headerlink" title="spark-default-conf（Client）"></a>spark-default-conf（Client）</h5><p>与<code>伪分布式-Standalone</code>配置基本一致，</p>
<p>此处我们的<code>Master</code>运行在<code>node1</code>节点上，<code>Namenode</code>运行在<code>node1</code>节点上。</p>
<p>因此需要修改一下<code>node0</code>为<code>node1</code>，</p>
<h5 id="Slave-1"><a href="#Slave-1" class="headerlink" title="Slave"></a>Slave</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node1 conf]$ mv slaves.template slaves</span><br><span class="line">[zhangsan@node1 conf]$ vim slaves </span><br><span class="line">node1</span><br><span class="line">node2</span><br><span class="line">node3</span><br></pre></td></tr></table></figure>

<p>将修改好的<code>spark</code>分发到其他两个节点。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node1 bigdata]$ scp -r spark node3:`pwd`/</span><br></pre></td></tr></table></figure>



<h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><h5 id="启动HDFS-1"><a href="#启动HDFS-1" class="headerlink" title="启动HDFS"></a>启动HDFS</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node1 sbin]$ start-dfs.sh </span><br></pre></td></tr></table></figure>

<h5 id="启动Spark-1"><a href="#启动Spark-1" class="headerlink" title="启动Spark"></a>启动Spark</h5><p>启动Master和Worker</p>
<p><strong>node1</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动HistoryServer</span></span><br><span class="line">[zhangsan@node1 sbin]$ ./start-history-server.sh </span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动Master和所有Worker</span></span><br><span class="line">[zhangsan@node1 sbin]$ ./start-all.sh </span><br><span class="line">[zhangsan@node1 sbin]$ jps</span><br><span class="line">5393 Worker</span><br><span class="line">5300 Master</span><br><span class="line">4582 NodeManager</span><br><span class="line">5447 Jps</span><br><span class="line">4216 SecondaryNameNode</span><br><span class="line">4376 ResourceManager</span><br><span class="line">4027 DataNode</span><br><span class="line">3871 NameNode</span><br><span class="line">14845 HistoryServer</span><br></pre></td></tr></table></figure>

<p><strong>node2</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node2 bigdata]$ jps</span><br><span class="line">4417 Worker</span><br><span class="line">3826 DataNode</span><br><span class="line">4476 Jps</span><br><span class="line">3966 NodeManager</span><br></pre></td></tr></table></figure>

<p><strong>node3</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node3 bigdata]$ jps</span><br><span class="line">3928 NodeManager</span><br><span class="line">4441 Jps</span><br><span class="line">4378 Worker</span><br><span class="line">3788 DataNode</span><br></pre></td></tr></table></figure>



<h4 id="Web-UI查看-1"><a href="#Web-UI查看-1" class="headerlink" title="Web UI查看"></a>Web UI查看</h4><p>可以在<code>windows</code>系统中配置一下<code>hosts</code>映射。</p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># C:\Windows\System32\drivers\etc\hosts</span><br><span class="line">192.168.179.100	node0</span><br><span class="line">192.168.179.101	node1</span><br><span class="line">192.168.179.102	node2</span><br><span class="line">192.168.179.103	node3</span><br></pre></td></tr></table></figure>



<p><strong>Master : 8080</strong></p>
<p><img src="/img/Spark/image-20220215120443007.png" alt="image-20220215120443007"></p>
<p><strong>Worker : 8081</strong></p>
<p><img src="/img/Spark/image-20220215120612101.png" alt="image-20220215120612101"></p>
<h4 id="测试集群"><a href="#测试集群" class="headerlink" title="测试集群"></a>测试集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[zhangsan@node1 bin]$ ./spark-shell --master spark://node1:7077</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">scala&gt; </span><span class="language-bash">var wordcount = sc.textFile(<span class="string">&quot;hdfs:///input/bigdata.txt&quot;</span>).flatMap(line =&gt; line.split(<span class="string">&quot; &quot;</span>)).map(word =&gt; (word,1)).reduceByKey(_+_)</span></span><br><span class="line">wordcount: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[11] at reduceByKey at &lt;console&gt;:24</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">scala&gt; </span><span class="language-bash">wordcount.collect()</span></span><br><span class="line">res3: Array[(String, Int)] = Array((hello,2), (bigdata,2), (study,2))  </span><br></pre></td></tr></table></figure>

<p>可以在 <a target="_blank" rel="noopener" href="http://node1:4040/">http://node1:4040</a> 下查看<code>driver</code>下job的运行情况。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">XiaoQu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://www.studybigdata.cn/Spark/Spark_Env_Standalone/">http://www.studybigdata.cn/Spark/Spark_Env_Standalone/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Spark%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/">Spark环境搭建</a></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Spark/Spark_Env_Local/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Spark环境搭建（一）Local模式</div></div></a></div><div class="next-post pull-right"><a href="/Spark/Spark_Env_YARN/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Spark环境搭建（三）Spark On YARN模式</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/Spark/Spark_Env_Local/" title="Spark环境搭建（一）Local模式"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-15</div><div class="title">Spark环境搭建（一）Local模式</div></div></a></div><div><a href="/Spark/Spark_Env_Windows_Dev/" title="Spark环境搭建（四）Spark开发环境搭建"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-23</div><div class="title">Spark环境搭建（四）Spark开发环境搭建</div></div></a></div><div><a href="/Spark/Spark_Env_YARN/" title="Spark环境搭建（三）Spark On YARN模式"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-15</div><div class="title">Spark环境搭建（三）Spark On YARN模式</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/jin.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">XiaoQu</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">90</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">50</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">23</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/A-stranger"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Spark环境搭建（二）Standalone模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F"><span class="toc-number">1.1.</span> <span class="toc-text">伪分布式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">配置</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#spark-env-sh%EF%BC%88Server%EF%BC%89"><span class="toc-number">1.1.0.1.1.</span> <span class="toc-text">spark-env.sh（Server）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#spark-default-conf%EF%BC%88Client%EF%BC%89"><span class="toc-number">1.1.0.1.2.</span> <span class="toc-text">spark-default-conf（Client）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Slave"><span class="toc-number">1.1.0.1.3.</span> <span class="toc-text">Slave</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8Spark%E9%9B%86%E7%BE%A4"><span class="toc-number">1.1.0.2.</span> <span class="toc-text">启动Spark集群</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8HDFS"><span class="toc-number">1.1.0.2.1.</span> <span class="toc-text">启动HDFS</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8History-Server"><span class="toc-number">1.1.0.2.2.</span> <span class="toc-text">启动History Server</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8Spark"><span class="toc-number">1.1.0.2.3.</span> <span class="toc-text">启动Spark</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web-UI%E6%9F%A5%E7%9C%8B"><span class="toc-number">1.1.0.3.</span> <span class="toc-text">Web UI查看</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95"><span class="toc-number">1.1.0.4.</span> <span class="toc-text">测试</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-number">1.2.</span> <span class="toc-text">集群部署</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.0.1.</span> <span class="toc-text">Spark配置</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#spark-env-sh%EF%BC%88Server%EF%BC%89-1"><span class="toc-number">1.2.0.1.1.</span> <span class="toc-text">spark-env.sh（Server）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#spark-default-conf%EF%BC%88Client%EF%BC%89-1"><span class="toc-number">1.2.0.1.2.</span> <span class="toc-text">spark-default-conf（Client）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Slave-1"><span class="toc-number">1.2.0.1.3.</span> <span class="toc-text">Slave</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8"><span class="toc-number">1.2.0.2.</span> <span class="toc-text">启动</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8HDFS-1"><span class="toc-number">1.2.0.2.1.</span> <span class="toc-text">启动HDFS</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8Spark-1"><span class="toc-number">1.2.0.2.2.</span> <span class="toc-text">启动Spark</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Web-UI%E6%9F%A5%E7%9C%8B-1"><span class="toc-number">1.2.0.3.</span> <span class="toc-text">Web UI查看</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E9%9B%86%E7%BE%A4"><span class="toc-number">1.2.0.4.</span> <span class="toc-text">测试集群</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/latex/" title="No title">No title</a><time datetime="2023-11-04T03:43:20.952Z" title="Created 2023-11-04 11:43:20">2023-11-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Python/File_Demo/" title="No title">No title</a><time datetime="2023-10-29T12:14:04.028Z" title="Created 2023-10-29 20:14:04">2023-10-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Python/PaddlePaddle_JupyterNotebook/" title="PaddlePaddle Jupyter NoteBook">PaddlePaddle Jupyter NoteBook</a><time datetime="2023-06-26T09:14:00.000Z" title="Created 2023-06-26 17:14:00">2023-06-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/ChatGPT/" title="No title">No title</a><time datetime="2023-06-25T07:47:22.975Z" title="Created 2023-06-25 15:47:22">2023-06-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Python/Web_Framework/" title="Web Framework">Web Framework</a><time datetime="2023-06-24T11:14:00.000Z" title="Created 2023-06-24 19:14:00">2023-06-24</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By XiaoQu</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>