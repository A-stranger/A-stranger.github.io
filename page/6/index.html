<!DOCTYPE html><html lang="zh-Hans" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>学习大数据 - StudyBigData</title><meta name="author" content="XiaoQu"><meta name="copyright" content="XiaoQu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="学习大数据">
<meta property="og:url" content="http://www.studybigdata.cn/page/6/index.html">
<meta property="og:site_name" content="学习大数据">
<meta property="og:locale">
<meta property="og:image" content="http://www.studybigdata.cn/img/jin.jpg">
<meta property="article:author" content="XiaoQu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.studybigdata.cn/img/jin.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://www.studybigdata.cn/page/6/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="code-qvYtDCUlcS"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?057fccfc2b1bef4c0d79224d80660be0";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '学习大数据',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-01-15 18:48:28'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/jin.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">30</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">17</div></a></div></div><hr/></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">学习大数据</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/Spark/PySpark/Spark_Python_RDD_Case/" title="PySpark RDD综合案例">PySpark RDD综合案例</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/PySpark/">PySpark</a></span></div><div class="content">RDD 综合案例基于物品的协同过滤123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import osfrom pyspark import SparkContext, SparkConfimport pandas as pdfrom scipy import statsfile_path = &quot;&quot;def set_spark_context(env):    global file_path    sparkConf = SparkConf()    sparkConf.setAppName(&quot;movie_recommend&quot;)    if env == &#x27;local&#x27; ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/Spark/PySpark/Spark_Python_QA/" title="Spark Python QA">Spark Python QA</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/PySpark/">PySpark</a></span></div><div class="content">Spark Python QAQ: PySpark: java.lang.OutofMemoryError: Java heap space1PySpark: java.lang.OutofMemoryError: Java heap space

A1spark_conf.setAppName(&quot;recommend&quot;).setMaster(&quot;local[*]&quot;).set(&#x27;spark.executor.memory&#x27;, &#x27;12g&#x27;).set(&#x27;spark.driver.memory&#x27;, &#x27;14g&#x27;)




Q:  Please install psutil to have better support with spilling1UserWarning: Please install psutil to have better support with spilling

A1pip install psutil




Q: {0}.{1} does not e ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/Spark/PySpark/Spark_Python_Rdd/" title="PySpark RDD">PySpark RDD</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/PySpark/">PySpark</a></span></div><div class="content">RDD
A Resilient Distributed Dataset (RDD), the basic abstraction in Spark. Represents an immutable(不可变的), partitioned collection(集合) of elements that can be operated o in parallel. This class contains the basic operations available on all RDDs, such as map, filter, and persist. 
In addition,
PairRDDFunctions(类) contains operations available only on RDDs of key-value pairs, such as groupByKey and join; 
DoubleRDDFunctions contains operations available only on RDDs of Doubles; 
SequenceFileRDDFunc ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/HBase/HBase_Query/" title="HBase 数据查询">HBase 数据查询</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/HBase/">HBase</a></span></div><div class="content">HBase数据查询数据准备创建表创建Student表，两个列族Info和Score；
12hbase(main):047:0&gt; create &#x27;Student&#x27;,&#x27;Info&#x27;,&#x27;Score&#x27;0 row(s) in 2.3500 seconds

插入数据批量插入

   
      No
      Info
      Score
   
   
      name
      age
      Hadoop
      HBase
      Spark
   
   
      001
      qiaofeng
      30
      93
      85
      70
   
   
      002
      duanyu
      27
      95
      98
      50
   
   
      003
      wangyuyan
      18
      95
      97
      92
   </div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/Spark/Spark_Env_Local/" title="Spark环境搭建（一）Local模式">Spark环境搭建（一）Local模式</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">Spark环境搭建（一）Local模式







Term
Meaning



Application
User program built on Spark. Consists of a driver program and executors on the cluster.


Application jar
A jar containing the user’s Spark application. In some cases users will want to create an “uber jar” containing their application along with its dependencies. The user’s jar should never include Hadoop or Spark libraries, however, these will be added at runtime.


Driver
The process running the main() function of the application and crea ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/Spark/Spark_Env_YARN/" title="Spark环境搭建（三）Spark On YARN模式">Spark环境搭建（三）Spark On YARN模式</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">Spark环境搭建（三）Spark On YARN模式

伪分布式配置Spark的Master由YARN的ResourceManager替代，Worker由NodeManager替代。
spark-env.sh1234HADOOP_CONF_DIR=/opt/bigdata/hadoop/default/etc/hadoopYARN_CONF_DIR=/opt/bigdata/hadoop/default/etc/hadoop# 日志服务器HistoryServer配置SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node0:9000/shared/spark-logs&quot;

spark-defaults.conf12345678[zhangsan@node0 conf]$ vim spark-defaults.confspark.master                     yarn# spark app执行的事件日志会存放到指定的位置spark.eventLog.enabled     ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/Spark/Spark_Env_Windows_Dev/" title="Spark环境搭建（四）Spark开发环境搭建">Spark环境搭建（四）Spark开发环境搭建</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">Spark环境搭建（四）Spark开发环境搭建



Windows练习环境Hadoop解压完Hadoop后，使用该网站中的bin目录替换掉原来的bin目录。
1https://github.com/cdarlint/winutils

环境变量
HADOOP_HOME

PATH


将 HADOOP_HOME/sbin 及     HADOOP_HOME/bin 目录追加到PATH变量后。
Spark
SPARK_HOME

PATH


将 SPARK_HOME/sbin 及 SPARK_HOME/bin 目录追加到PATH变量后。

Spark-Shell
项目创建查看Scala版本1234567891011[zhangsan@node0 bin]$ ./spark-shell Spark context Web UI available at http://node0:4040Spark context available as &#x27;sc&#x27; (master = local[*], app id = local-1648259787148).Spark ses ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/HBase/HBase_Exercise/" title="HBase_Shell 练习">HBase_Shell 练习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/HBase/">HBase</a></span></div><div class="content">HBase 练习查看HBase版本12hbase(main):033:0&gt; version1.4.13, r38bf65a22b7e9320f07aeb27677e4533b9a77ef4, Sun Feb 23 02:06:36 PST 2020

集群状态12hbase(main):034:0&gt; status1 active master, 0 backup masters, 1 servers, 0 dead, 4.0000 average load

创建Teacher表，包含一个列族Info12hbase(main):041:0&gt; create &#x27;Teacher&#x27;,&#x27;Info&#x27;0 row(s) in 2.3430 seconds

创建Student表，两个列族Info和Score；列族Info的数据在读取时关闭缓存BLOCKCACHE。列族Score内的数据保留2个版本VERSIONS12hbase(main):047:0&gt; create &#x27;Student&#x27;,&#123;NAME=&gt;& ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/Spark/Spark_Env_Standalone/" title="Spark环境搭建（二）Standalone模式">Spark环境搭建（二）Standalone模式</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Spark/">Spark</a></span></div><div class="content">Spark环境搭建（二）Standalone模式

伪分布式配置包括 Hadoop配置，Master, Worker的通信地址和Web UI的地址
spark-env.sh（Server）1234567# 如果Worker提示JAVA_HOME is not set, 在此文件配置一下JAVA_HOME# JAVA_HOME=$&#123;JAVA_HOME&#125;HADOOP_CONF_DIR=/opt/bigdata/hadoop/default/etc/hadoop #读写HDFSSPARK_MASTER_HOST=node0  # Master节点# 日志服务器HistoryServer会去指定的位置读取执行事件日志SPARK_HISTORY_OPTS=&quot;-Dspark.history.fs.logDirectory=hdfs://node0:9000/shared/spark-logs&quot;

spark-default-conf（Client）1234567[zhangsan@node0 conf]$ mv spark-defaults.conf.tem ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/Hadoop/Hadoop_HA/" title="Hadoop NameNode HA">Hadoop NameNode HA</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-23T07:55:26.000Z" title="Created 2022-03-23 15:55:26">2022-03-23</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="content">Hadoop HANameNode HA修改配置文件core-site.xml1234567891011121314&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://hdfscluster&lt;/value&gt;&lt;/property&gt;&lt;property&gt;     &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;    &lt;value&gt;/opt/bigdata/hadoop/default/tmp/jn&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;    &lt;value&gt;node1:2181,node2:2181,node3:2181&lt;/value&gt;&lt;/property&gt;



hdfs-site.xml12345 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/5/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/#content-inner">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/#content-inner">7</a><a class="extend next" rel="next" href="/page/7/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/jin.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">XiaoQu</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">64</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">30</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">17</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/A-stranger"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/FrontEnd/LayUI/" title="No title">No title</a><time datetime="2023-01-09T07:53:19.531Z" title="Created 2023-01-09 15:53:19">2023-01-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Hadoop/Hadoop_File/" title="No title">No title</a><time datetime="2022-12-27T05:03:07.423Z" title="Created 2022-12-27 13:03:07">2022-12-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Hadoop/Hadoop_HDFS_Files/" title="No title">No title</a><time datetime="2022-12-22T10:53:55.305Z" title="Created 2022-12-22 18:53:55">2022-12-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Hadoop/Hadoop_HDFS_Train/" title="No title">No title</a><time datetime="2022-12-21T12:50:03.399Z" title="Created 2022-12-21 20:50:03">2022-12-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/Spark/Spark_SQL/" title="Spark SQL">Spark SQL</a><time datetime="2022-12-20T15:06:26.000Z" title="Created 2022-12-20 23:06:26">2022-12-20</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            <a class="card-more-btn" href="/categories/" title="More">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Django/"><span class="card-category-list-name">Django</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Flume/"><span class="card-category-list-name">Flume</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/HBase/"><span class="card-category-list-name">HBase</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hadoop/"><span class="card-category-list-name">Hadoop</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hive/"><span class="card-category-list-name">Hive</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Kettle/"><span class="card-category-list-name">Kettle</span><span class="card-category-list-count">10</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Linux/"><span class="card-category-list-name">Linux</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/MongoDB/"><span class="card-category-list-name">MongoDB</span><span class="card-category-list-count">3</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Django/" style="font-size: 1.1em; color: #999">Django</a> <a href="/tags/Flume/" style="font-size: 1.1em; color: #999">Flume</a> <a href="/tags/HBase/" style="font-size: 1.5em; color: #99a9bf">HBase</a> <a href="/tags/HBase-Region%E7%AE%A1%E7%90%86/" style="font-size: 1.1em; color: #999">HBase Region管理</a> <a href="/tags/HBase-Shell/" style="font-size: 1.23em; color: #999ea6">HBase Shell</a> <a href="/tags/HBase-Thrift/" style="font-size: 1.1em; color: #999">HBase Thrift</a> <a href="/tags/HBase%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 1.1em; color: #999">HBase伪分布式</a> <a href="/tags/HBase%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 1.1em; color: #999">HBase完全分布式</a> <a href="/tags/HBase%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99/" style="font-size: 1.1em; color: #999">HBase数据读写</a> <a href="/tags/HBase%E6%9E%B6%E6%9E%84/" style="font-size: 1.1em; color: #999">HBase架构</a> <a href="/tags/HBase%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 1.1em; color: #999">HBase环境搭建</a> <a href="/tags/HBase%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/" style="font-size: 1.1em; color: #999">HBase集群管理</a> <a href="/tags/Hadoop/" style="font-size: 1.37em; color: #99a4b2">Hadoop</a> <a href="/tags/Linux/" style="font-size: 1.23em; color: #999ea6">Linux</a> <a href="/tags/MapReduce/" style="font-size: 1.23em; color: #999ea6">MapReduce</a> <a href="/tags/MongoDB-Python/" style="font-size: 1.1em; color: #999">MongoDB Python</a> <a href="/tags/MongoDB%E4%BD%BF%E7%94%A8/" style="font-size: 1.1em; color: #999">MongoDB使用</a> <a href="/tags/MongoDB%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/" style="font-size: 1.1em; color: #999">MongoDB环境部署</a> <a href="/tags/PySpark/" style="font-size: 1.23em; color: #999ea6">PySpark</a> <a href="/tags/Quartz/" style="font-size: 1.23em; color: #999ea6">Quartz</a> <a href="/tags/Source-Code/" style="font-size: 1.1em; color: #999">Source Code</a> <a href="/tags/Spark-DataFrame/" style="font-size: 1.1em; color: #999">Spark DataFrame</a> <a href="/tags/Spark-GraphFrames/" style="font-size: 1.1em; color: #999">Spark GraphFrames</a> <a href="/tags/Spark-SQL/" style="font-size: 1.1em; color: #999">Spark SQL</a> <a href="/tags/Spark%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 1.5em; color: #99a9bf">Spark环境搭建</a> <a href="/tags/Spark%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/" style="font-size: 1.1em; color: #999">Spark环境部署</a> <a href="/tags/YARN/" style="font-size: 1.1em; color: #999">YARN</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" style="font-size: 1.23em; color: #999ea6">环境搭建</a> <a href="/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/" style="font-size: 1.23em; color: #999ea6">过滤器</a> <a href="/tags/%E9%99%90%E5%AE%9A%E7%AC%A6/" style="font-size: 1.23em; color: #999ea6">限定符</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/01/"><span class="card-archive-list-date">January 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/12/"><span class="card-archive-list-date">December 2022</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/11/"><span class="card-archive-list-date">November 2022</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/10/"><span class="card-archive-list-date">October 2022</span><span class="card-archive-list-count">12</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/03/"><span class="card-archive-list-date">March 2022</span><span class="card-archive-list-count">38</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">64</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-01-15T10:48:28.290Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By XiaoQu</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>